AI-Powered Image GeneratorTalrn ML Internship Task Assessment SubmissionThis project is a complete, full-stack application for text-to-image generation, built to demonstrate proficiency in open-source generative AI models, Deep Learning frameworks (PyTorch), web development (Streamlit), and adherence to ethical AI principles.1. Project Overview and ArchitectureThe system follows a classic Machine Learning service architecture:Frontend (Streamlit): Provides a simple, interactive web UI (app.py) for users to enter prompts and adjust parameters like style guidance, number of steps, and image count.Backend (Python/PyTorch): The ImageGenerator class (generator.py) handles all core logic.Model: Loads the Stable Diffusion v1.5 pipeline using the diffusers library.Device Management: Automatically detects and utilizes an available CUDA GPU, falling back gracefully to the CPU.Generation: Executes the diffusion process with user-specified settings.Post-processing: Applies the watermarking layer and saves the image/metadata.2. Technology Stack and Model DetailsComponentTechnologyRoleDeep Learning FrameworkPyTorchCore framework for model execution and GPU acceleration.ModelStable Diffusion v1.5Open-source latent diffusion model for text-to-image synthesis.Model LibraryHugging Face DiffusersHigh-level API used to easily load and run the diffusion pipeline.Web InterfaceStreamlitRapid prototyping framework for the web UI.UtilityPIL (Pillow)Used for watermarking and handling image exports (PNG/JPEG).3. Setup and Installation StepsThis project requires Python 3.8+ and pip.Clone the Repository:git clone [YOUR_GITHUB_REPO_URL]
cd ai-image-generator
Create a Virtual Environment:python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
Install Dependencies:A requirements.txt file should be generated containing: torch, diffusers, transformers, streamlit, accelerate, pillow.If you have an NVIDIA GPU (Recommended):pip install torch torchvision torchaudio --index-url [https://download.pytorch.org/whl/cu118](https://download.pytorch.org/whl/cu118)
pip install -r requirements.txt
If you are using CPU or a non-NVIDIA GPU:pip install torch torchvision torchaudio --index-url [https://download.pytorch.org/whl/cpu](https://download.pytorch.org/whl/cpu)
pip install -r requirements.txt
Run the Application:streamlit run app.py
The application will open in your default web browser.4. Hardware Requirements (GPU/CPU Specifications)ModeMinimum RequirementPerformanceImplementation PathGPU (Preferred)NVIDIA GPU with 4GB+ VRAM (e.g., GTX 1060, RTX 3050).Fast (10-30 seconds per image).PyTorch CUDA and torch_dtype=torch.float16.CPU (Fallback)8GB+ System RAM.Slow (2-5 minutes per image).PyTorch CPU and torch_dtype=torch.float32.The system automatically detects the device and sets the appropriate precision (float16 for GPU, float32 for CPU) for optimal performance and compatibility.5. Usage Instructions with Example PromptsStart the app with streamlit run app.py.In the main panel, enter your core prompt (e.g., A majestic lion wearing a crown).In the sidebar, adjust:Number of Images: How many images to generate (1-4).Style Preset: Select a style like "Photorealistic" to enhance the output quality automatically (e.g., A majestic lion wearing a crown, highly detailed, 4K, professional photography...).(Optional) Use the Negative Prompt field to exclude unwanted elements (e.g., blurry, distorted).Click "Generate Images."Monitor the real-time progress bar.View the watermarked results and download the original file as PNG or JPEG.6. Prompt Engineering Tips and Best PracticesPrompt engineering is critical for obtaining high-quality results from diffusion models.ComponentDescriptionExampleSubjectWhat is the main focus?A grumpy cat...Style/MediumWhat look should it have?...in the style of watercolor, cinematic lighting.CompositionHow is the scene set?...full body portrait, isometric view.Quality Tags (Auto-added)Technical descriptors for realism....4k, highly detailed, trending on ArtStation.The App's Style Presets implement these techniques automatically.7. Ethical AI UseThis project adheres to ethical AI principles through the following mechanisms:Content Filtering: The Stable Diffusion pipeline uses a pre-trained Safety Checker module. This tool automatically checks the generated output against a list of sensitive and unsafe content prompts, replacing flagged images with a black placeholder, ensuring responsible use.AI Origin Watermarking: Every generated image is post-processed by the add_watermark function to include a small text overlay, "AI Generated | Talrn", indicating its synthetic origin.Responsible Use Guidelines: Users are instructed via the negative prompt to avoid generating content that is low-quality, blurry, or distorted, and are ethically bound to avoid generating harmful or illegal content.8. Limitations and Future ImprovementsLimitationsGeneration Time: CPU generation is extremely slow (2-5 mins per image). A powerful GPU is necessary for practical use.Memory Footprint: The model requires several gigabytes of VRAM/RAM, making it unsuitable for very low-spec machines.Stylistic Bias: Stable Diffusion v1.5 has inherent biases based on its training data.Future ImprovementsStyle Transfer Feature: Implement the ability to upload a source image and apply the generated image's style to it.Model Fine-Tuning: Fine-tune the model on a custom, smaller dataset (e.g., specialized architectural renders or company branding) to generate more focused, domain-specific outputs.Cloud Deployment: Package the application using Docker and deploy to a cloud service (like Google Cloud Run or AWS SageMaker) to eliminate local hardware dependency.UI Enhancements: Add user-specified filenames for exported images and a dedicated gallery view.
